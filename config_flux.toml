[training_config]
pretrained_model_name_or_path = "/content/models/flux1-dev.safetensors"
clip_l = "/content/models/text_encoders/clip_l.safetensors"
ae = "/content/models/ae.safetensors"
t5xxl = "/content/models/text_encoders/t5xxl_fp16.safetensors"
output_dir = "/content/output"
output_name = "hius"
max_train_epochs = 10
train_batch_size = 1
seed = 42
save_every_n_epochs = 1
mixed_precision = "bf16"
save_precision = "bf16"
sdpa = true
max_data_loader_n_workers = 2
persistent_data_loader_workers = true
gradient_checkpointing = true
highvram = true
fp8_base = true
network_train_unet_only = true
cache_latents_to_disk = true

[optimizer_config]
optimizer_type = "AdamW8bit"
optimizer_args = ""
learning_rate = 1e-5
text_encoder_lr = 1e-5
lr_scheduler = "cosine"
lr_warmup_steps = 0

[network_config]
network_dim = 32
network_module = "networks.lora_flux"
network_alpha = 16
network_args = ""

[sample_config]
sample_every_n_steps = 100
num_prompts = 1
sample_at_first = true
sample_prompts = "/content/colab_ui/config/sample_prompt.toml"
sample_sampler= "euler"

[flux_config]
guidance_scale = 1.0
discrete_flow_shift = 3.1582
timestep_sampling = "shift"
model_prediction_type = "raw"
cache_text_encoder_outputs = false
cache_text_encoder_outputs_to_disk = false

[log_config]
log_with = "tensorboard"
wandb_api_key = ""
logging_dir = "/content/colab_ui/logs"
wandb_run_name = ""

[advanced_config]
metadata_title = ""
metadata_author = ""
metadata_description = "support by lahteam.vn"
training_comment = "support by lahteam.vn"
resume = ""
save_state = false


[dataset_config]
train_data_dir = ""
reg_data_dir = ""
caption_extension = ".txt"
num_repeats = 10
flip_aug = false
keep_tokens = 0
